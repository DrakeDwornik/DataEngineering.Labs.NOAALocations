import pandas as pd
import os
import json
from IPython.display import JSON
import pickle


# implement me
def read_json(file_path):
    with open(file_path) as file:
        json_object = json.load(file)
    return json_object


file_path = os.path.join('./', 'data', 'locations', 'locations_04.json')
json_contents = read_json(file_path)


JSON(json_contents)


df = pd.DataFrame(json_contents["results"])


df


df = pd.DataFrame(json_contents['results'])



df



df[df['name'].str.contains("Durham")]


# implement me
def read_all_json_files(JSON_ROOT):
    files_all = os.listdir(JSON_ROOT)
    # print(files_all)
    files_json = ([file for file in files_all if file.endswith(".json")])
    first = True
    # print(files_json)
    for file in files_json:
        # print(file)
        if first:
            # print(first)
            json_contents = read_json(f"{JSON_ROOT}/{file}")
            df = pd.DataFrame(json_contents['results'])
            df["source"] = file
            first = False
        else:
            # print(first)
            # print(file)
            json_contents = read_json(f"{JSON_ROOT}/{file}")
            df2 = pd.DataFrame(json_contents['results'])
            df2["source"] = file
            df =df.append(df2, ignore_index = True)
    return df


df = read_all_json_files('./data/locations')


# Validate the shape of the DataFrame here.
df


# Show the first few records
df.head()


# Show the last few records
df.tail()


df.nunique()
#38862 = total number of rows


# another way to determine there are no duplicate records
len(df) - len(df.drop_duplicates())


# 
df[df["id"] == "CITY:TU000041"]
#locations_01.json



# 
df[df["id"] == "CLIM:0405"]
#locations_02.json


# 
df["source"].nunique()
#39


# 
df[df["source"] == "locations_38.json"].count()
#862



# export DataFrame to a pickled file called locations_data_frame.pickle. Save it to the data directory.
def write_pickle(dataframe):
    try:
        file = open("./locations_dataframe.pkl", "wb")
    except OSError as e:
        print("Error opening the file. Please ensure the file exists and has appropriate permissions.")
        logging.error(e)
    else:
        # pickle.dump()
        # pickle.dump()
        pickle.dump(dataframe, file)
    finally:
        file.close() if file else logging.warning("No file resource available to close.")


write_pickle(df)


def load_pickle(file_with_path):
    pickle_contents = None
    file = None
    try:
        file = open(file_with_path, "rb")
    except OSError as e:
        print("Error opening the file. Please ensure the file exists and has appropriate permissions.")
        logging.error(e)
    else:
        # print(file)
        # print(pickle.load(file))
        pickle_contents = pickle.load(file)
    finally:
        file.close() if file else logging.warning("No file resource available to close.")
        return pickle_contents


df_test = load_pickle("./locations_dataframe.pkl")
df_test



